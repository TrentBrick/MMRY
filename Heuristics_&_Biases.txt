Affect Heuristic :- Benefits and Risks are irrationally correlated.
Observation Selection Effect :- we forget that we are in a unique observer position
Scope neglect's 3 explanations :- 1. our brains are biologically incapable of scaling up our emotions with numbers, instead use "valuation by prototype". This leads to an "empathy cap". Logarithmic increases in emotion vs. numbers. 2. Purchase of moral satisfaction 3. Good cause dump (x amount into this general cause category)
Overconfidence example (general knowledge) :- of 1000 general knowledge questions; 426 of the true values lay outside the subjects' 98% confidence intervals. If properly "calibrated" there should have been 20 (2% vs. 42%). Same with upper/lower bounds and min/max values. After teaching and practice still 19% error. Same results also found by experts.
Planning fallacy is... :- Overconfidence applied to planning. Only 13% of students finished by 50% prob. level, 45% by 99% prob. "Reality, it turns out, usually delivers results somewhat worse than the 'worst case'. 
Bystander apathy smoking room example :- If alone 75% left. With 3 naive subjects only 38%. With confederates only 10% of the time. 
Bystander apathy seizure example :- 85% of the time helped by an individual. Only 31% of the time by 5 bystanders. Due to diffusion of responsibility and pluralistic ignorance. 
Conjunction fallacy :- Eg. Linda the feminist bank teller and the dice rolls. We substitute judgement of what is most probable with what is most representative. More details add to the likelihood when this violates the conjunction rule of probability. P(A) >= P(A n B). We should invest in preparation for broad event response rather than specific movie scene like events. We overestimate that seven 90% prob. events will all occur and underestimate that at least one of seven 10% prob. events will occur. 
Percentage of entrepreneurial ventures. 
Availibility heuristic :- confuse probability with availability of information from memory. Only think future evenst are likely if we can remember them. Without hindsight we should have attended to *every* equally likely O-ring disaster and 9/11 threat. 
Hindsight bias consequence legal :- Prob. of flood damage to a bridge (actual legal case). Experimental group told flood did occur. City begligent if probability was over 10%. 76% of control group said it was so unlikely the city is not responsible. Only 43% of the experimental group did. Another group was told about the flood and taught about hindsight bias. Stil 44% thought the city was negligent. 
Hindsight bias consequence in general :- dont learn that Black Swans exist and randomness can occur. Try to adjust for specific incident often with an over response. 
Black swans are a combo of... :- Hindsight bias and availability heuristic. Hindsight makes the past predictable and availability makes us think we can predict the future.
Yudowsky's scope insensitivity dichotomy :- "People who would never dream of hurting a child hear of an existential risk, and say, 'Well, maybe the human species doesn't really deserve to survive'". 
What is non-extensional reasonsing :- People do not evaluate events, but descriptions of events.Teh exension of humanity's extinction includes the death of yourself, your family, friends, political party, country, everything. 
How to increase the effects of anchoring, adjustment, and contamination? :- create more cognitive demands like remembering strings of numbers. 
Why can we only picture the world ending by a terminator-like scenario? :- this is a combination of the availibility and anchoring heuristics. 
What are the two forms of confirmation bias? :- cold - this is unemotional eg. the 2-4-6 rule. hot - this is emotional and more resistant to change. 
What is confirmation bias? :- only seek to confirm rather than falsify. Eg. test the 2-4-6 rule to confirm their theory rather than break it.
What is disconfirmation bias? :- "In the former case, the person asks if the evidence *compels* one to accept the conclusion, whereas in the latter case, the person asks instead if the evidence *allows* one to accept the conclusion". 
What are the two problems with disconfirmation bias? :- 1. You can use the same evidence and extract very different conclusions. 2. The smarter you are the less likely you are to change your mind. No matter how compelling an argument is it does not make it any more or less true. The only wayt to truth is a change of belief. Not all changes of belief get closer to truth but all truth comes from changes in belief. 
Example of how quickly we make up our minds and have a natural irrational bias :- 24 colleagues, 2 real job offers. Probability they would choose one vs. the other, mean confidence in one was 66% yet only 1/24 chose the job with a lower probability = 96% accuracy. (a rare example of human underestimation!). This does not fare well for researchers who we should trust to look just as hard at one side of the data as the other. 
How should we be addressing bias in the real world if I am running a company? :- get everyone to write down their own independent thoughts first. Then get everyone to talk about the problem for as long as possible without talking about a solution. 
Attitude strength effect :- the stronger the voicing of an opinion, the more confirmation and disconfirmation bias is apparent. 
Sophistication effect :- those who are more sophisticated are more prone to confirmation adn disconfirmation. 
 